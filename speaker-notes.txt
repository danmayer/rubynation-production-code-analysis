# These are generated from this JS
# $('.slide-notes').each( function( index ) { console.log("\n\nslide: "+index); console.log($(this).html()) })

slide: 0

	We have all seen spaghetti code. It is hard to understand and
      follow all the code paths. It is difficult to change and
	maintain.

	As projects grow and age it is very difficult to entirely
      avoid. Untangling it is hard but code analysis the code can help.

      First I want to briefly explain
      how a project can reach a point where there is over 200KLOC that
      can be removed. Then I can explain some processes to help find
      and remove unnecessary complexity.
        


slide: 1  

	Yes, we have a MonoRail app. A very large app that has grown
      for years.

	Actually we have more than one, how did we get here. A bit of
 history.

	The application began as a fork of an existing project to
	quickly validate an idea.
	
	That grew into a consumer business, which is what most people
      know as LivingSocial today.

	That app grew a lot and had many teams working to extend its
      functionality.

	Eventually it was forked into multiple other applications.
	
      This means all these apps share some of the same
      code, but after each split they have less responsibility.

	Which code is needed for the smaller slice of responsibilities, what
      can be removed from the parent or app?

	If you keep going like this without ever cleanup up the apps
	no longer necessary code. You will eventually crash.
	
	Looking production runtime can help tell you.

	(images obviously taken from the Simpsons)
        


slide: 2  

	Beyond Monorails, dead code can slip into a system many
      ways. I am not really going into all the details, but suffice to
      say. Every system I have worked on grows and at some point has
      unnecessary code tucked away into the corners at some
      point. Features that don't quite justify their UI complexity,
      pivoting away from some direction, either for business or
      development reasons. 
        


slide: 3  

	Their is a pretty hilarious article titled "programming still
      sucks" by Peter Welch, recently making it around the net.

	In it he makes the analogy of a team
      building a bridge, not knowing what they are doing building half
      suspension and half support bride.

	In the article he jokingly states, "all code is bad". That
      must mean...
        


slide: 4  

      ...Less code is better. Obviously if the code is doing work it has some value,
      but I don't think I have to spend much time time on why having less code
      &amp; simpler systems is better.
        


slide: 5  

	So if the problem is all code is bad and we agree less code is better, the
      solution is clean up dead code. Keeping only the code need.
	
	We can make our projects better by only working what we
      need. The code that is actively adding value to our
      business and users.

	Sounds good, let's delete all the code... Or some of it, which code...
        


slide: 6  

	In the article the bridge analogy continues, explaining why the
      team left the suspension cables up after switching to a support
      column bridge.
        


slide: 7  

	What really caught my attention in the article was this
      specific line.

	Nobody knows which parts.
	
	We don't have to settle for guessing, we can solve this
      problem... We can use data.
        


slide: 8  

	Hopefully that explains a bit about how one can end up in a
      place where they need data to help them know what is going on
      with their systems.
	
	I am going to go through some examples of processes we have
      used to find unused code. From very simple methods, to more
      complicated processes. Also, note if you run `rake stats` on a
      Rail app and have less than 3-5K lines of application code. You
      can probably just reason about all this in your head pretty
      easily and some of these tools might seem like overkill. We had
      apps pushing 80K lines of app code, excluding view layer,
      JS, CSS.
        


slide: 9  

	Just to show that this isn't some idea, these are processes we
	have been able to put into practice. Here is my history on one
	of our Monorails apps. I am pretty proud to have removed
	nearly 2 lines of code for every one added, while delivery
	additional functionality and faster performance.
        


slide: 10  

	  Also, wanted to point out getting code bases into shape. Is
	really a team effort. As a team we celebrate our code
	improvements. Pointing out and cheering on particularly good commits, faster tests,
	code deletion.

	  Linking to little victories in campfire all the
	way.
	  


slide: 11  

	One of the easiest ways to gain insight into what code is
      being used in production is checking with any of the 3rd party
      performance monitoring tools. In this case NewRelic but I am
      sure Skylight.io and Traceview can get you the same data. In
      this view you can sort transactions broken down by controller
      route by usage. Anything with 1 view in the last seven days likely isn't pulling its
      weight. It might be worth discussing the cost of those features
      with the business team.

	This view also doesn't show you what received 0 requests.
        


slide: 12  

        I created a gem to make this easy to check. You can download
      the CSV of NR transactions and it can compare it to your Rails
      routes. Finding any routes you have which are never hit.

	Running this on old production apps always seems to find some long
      forgotten routes.
        


slide: 13  

        Custom Stats instrumentation is very flexible. We are going to
      look at a number of techniques to gain insight into what your
      application is actually doing in production.
        


slide: 14  

	We use a number of tools for custom stats, that I wanted to
      quickly mention.
	
       I wanted to give a shout out to Etsy here, as we rely heavily on StatsD, and they
      have shared in great detail how they also use metrics to gain
      all sorts of code and business insights.

      StatsD is also extremely performant and while it can be lossy,
      we haven't ever run into performance issues while adding many metrics.
	
	Also, quickly here is some shared constants that will appear in
      several of the examples. Internally we have wrappers around
      our Redis and StatsD usage to deal with things like app name
      spacing, common error handling, configurations, etc.

	In these examples I am just using Redis and StatsD directly.
        


slide: 15  

	First up, not using NewRelic or another performance tool? No
    problem.
	
	We have a couple of ways we have added tracking on endpoints
      and timing in Rails. I think the simplest and cleanest example
      was done by <a href="https://twitter.com/jwhitmire">Jeff
    Whitmire</a>. Obviously 3rd party performance monitors give you a
    lot more details than this, but this lets you collect basic usage
    and performance stats. Make it easy to See what is being used or
      to configure alerts based on percentile performance changes.
        


slide: 16  

	If you run a sizable Rails app you likely run background
  jobs.

	Some jobs will come and go over time. It is pretty easy to
  remove code that queues a job, while leaving around the job code and
  related methods. It is easy to instrument how often something is
  processed, completed. With a bit more work you can record execution time around jobs or
  success/failures on completion.

	This is a simple example assuming Resque, but is pretty similar for all queueing frameworks.
        


slide: 17  

       Mailers like background jobs and come and go. Stating every
  mailer as it is sent lets you know when a mailer is no longer
      needed.

       Or perhaps which mailers you should spend more time
  improving based on the send volume. This is a simple example of hooking into
  action mailer to stat every mailer sent.
        


slide: 18  

       The view layer more than anywhere else can get quickly messy
  and hard to follow.

       Partials inside layouts, inside partials, and
  ajax... Oh My.

       A new view gets tested or moved and people aren't
  sure if the partial is used anywhere else. AB tests leave views
  behind.

       With activesupport
  notifications it is easy to stats every view file as it is
  rendered. Again beyond finding unused view code (and the related
  helpers), you get a nice picture of what your most important view
  components actually are.

       This shows you could either stat, or log which views are being used.
       


slide: 19  

	The view tracking pattern is simple and I wanted to reuse it
	a few places. So we have a nice little gem to quickly hook it
	up into Rails apps. It provides some helpers to output unused
	views by comparing the view renderings with the files you
	actually have on disk.

	Making it super simple to do dig into view
	layer cleanup, and all the related helpers and modules that go
	with it.
        


slide: 20  

	#note cut this slide if short on time
	I did want to briefly mention a little ActiveSupport oddity I
	found.
	
	ActiveSupport violated the principle of
	least surprise I felt as I was  working on this.

	Template files in the notifications include the full pathname and file
	extensions. For layout files it does not. It tripped me up a bit so I figured
	I would mention it. Flatfoot has some methods to help layouts
	even without extensions.
        


slide: 21  

	One problem with tracking only controllers and actions, is that
      the often serve multiple formats and request paths.

	For that,
      one of trackers can be useful. Tracking format specific
      endpoints, conditional paths, and bit of code really.

	We use the deprecated namespace in
      our apps to track helper methods, models, views. It
      also provides a quick way to jump into code cleanup. Grep the
      code for deprecated stats, check graphite and safely remove
      code no longer in use.
        


slide: 22  

	This isn't actually related to finding unused code, but I like
      this trick so much I wanted to share it.
	
	Shout out to Tyler Montgomery, who checked this great idea
  into our git one day.
	
	One off trackers, aren't only useful for finding unused
  code. It can be a great way to launch performance enhancements.

	To gather data on the performance of two implementations with
  production data sets. Simply split
  the code between old and new while sending the timing info to
  StatsD. Gather performance information against actual production
  usage and data, to determine the best algorithm and have a good idea
  of how much better it actually is.
        


slide: 23  

	Another piece of an application that can easily become a out
    of sync is translation keys. Over time, it is hard to know which
    translations are still in use.

	Translation keys
    end up causing a not fun memory bloat for production rails
    processes. That unchecked over time can be quite costly for
    overall performance.

	Chris Morris built Humperdink which has a
    number of uses, but is particularly well suited to help track down
    no longer used translation keys.

	Check out the gem for more details on how
    to track translations, but the above shows a bit of the basics.
        


slide: 24  

	That covers various custom stats so let's talk a little bit
      about logs.
	
	 Your application logs are a mine of information just waiting
      to help you out. When you have multiple applications and you are
      trying to refactor or remove old endpoints knowing, which
      clients and versions are using the application can be critical.

      Again if you don't have NR or 3rd party
      performance tools. You can get great rollups of performance for
      controllers and actions with Kibana, Splunk, or other log
      querying tools.
        


slide: 25  

	You can implement render_tracking, translation_key tracking,
      and most of the other mentioned systems just by logging data in
      query-able formats to your logs and crafting the correct queries.

	Logs can go deep when you are digging into specific problems like
      debugging exceptions.

	All your exceptions should link you back
      to the original logs related to the request causing the
      exceptions.
        


slide: 26  

	Trying to discover how the code reaches a path you never
      expect or intend it to reach anymore can be complicated. Perhaps
      a old client gem exists out there in the wild, or someone is
      linking to a url with params you thought were
      deprecated. Whatever the case you can log the caller inside a
      path to figure out the call path that got there. If you have a
      request_id, you can then tie that back to the initial entry
      point and parameters into your application.
        


slide: 27  

	Combine the deprecation logging with a good idea from <a href="http://www.twitter.com/geeksam">Sam Livingston-Gray</a>,
    which automatically builds the deprecation stat based on the
    caller. You end up with a really useful deprecation_trace helper
    you can use while investigating code to remove.
        


slide: 28  

	 	 One place I turn to logs is to know what is happening on a
      the system between applications or components. When deprecating
      old code or splitting up an app tracking down find edge usage
      can be tricky. Logs can be particularly useful for this level of
      information. Imprint helps trace across apps and components.
	 
	 Imprint builds on ideas from Twitter. Twitter created ZipKin,
      but most of the tooling is in the Scala world. Rails also
      provides a request_id which IMPRINT can use. Imprint makes it
      easy to capture a request trace and help propagate it through
      multiple systems. The gem helps simplify the process to integrate it into
      multiple tools.

	 We use imprint in our base internal api-client. This means
       all inter-app service calls will pass the current requests
       trace_id as a header to the server. The api service then uses
       this passed id while logging its requests.
         


slide: 29  

	Most of the above monitors focus on a particular piece of the
      puzzle. It takes effort to setup ahead of time and then time to
      collect and analyze the data.

	It seemed like a pattern could be
      abstracted, which would be more generally useful. Really I
      wanted to know how often a given line of code was being run in
      production.

	Ruby  
      better, while Coverage make this easy to do for tests, it has
      some bugs that prevent it being used for production. I ended up
      working with set_trace_fun and sampling a percentage of requests
      to get some great data.

	Unfortunately, the performance hit is pretty large for big
      applications. I am running this on Monorail size apps with about
      1% of requests being sampled. While I can run 60-90% of requests
      small Sinatra apps without noticing much of a performance
      impact.

	I am currently in progress with a native c extension which
      should significantly improve performance. I also think that
      using a sampling profiler based on time opposed to sampling full
      requests, which was built into Ruby 2.1, that I should be able
      to gather this data in production without a noticeable impact on
      application performance. If anyone has strong C skills and is
      interested in helping out, I am definitely in need of some help
      in this area. 
        


slide: 30  

	Coverband works as rack middleware. It decides whether to
      sample a request ass it comes in. When enabled for a request stores the
      coverage of code run during the entire request and sync it up to Redis
      at the end of the request.
	
	To configure coverband you can either put this config block
      where necessary of place it in `config/coverband.rb` which it
      gets picked up when you call Coverband.configure.

	`Coverband.parse_baseline` tells Coverband where to find a
      baseline recording of code coverage just from loading the
      application. A lot of Ruby code is run just loading the Rails
      app, and that isn't capture during the request cycle. So we can
      just record that once and merge it in with live coverage data.

	Setting it up, you can see I provide different settings for
      development and production. It makes it easier to test and
      verify in development with a large sample rate.

	A couple settings to note, `config.startup_delay` Rails
      defines a lot of methods dynamically on the first few requests
      we ignore d because they can run much slower with Coverband.

	percentage is the number of requests that we will sample and
      record with coverband.

	ignore lets you not record section of code you wish to
      skip. Skipping heavy non app code like vendor or lib can also
      help to reduce the performance impacts.
        


slide: 31  

	After installing the gem and creating a config file. You want
	to include the rake tasks into your `Rakefile` and you want to
	setup the middleware.

	In this example I am setting up the middleware as early as
      possible in the `config.ru`. Really unless you have lots of
      custom rack middleware setting it up anywhere in your middleware
      stack should be find. 
        


slide: 32  

	Coverband can give you interesting information and help you to
      find hotspots of code in development mode as well. If you enable
      verbose at the end of each request that coverband records it
      outputs to the configured log a bunch of useful stats. Breaking
      down files that were called the most, as well as the most common
      lines called in heavily used files.
        


slide: 33  

	Here is a list of the gems, I mentioned during the talk. These
      are all open source released by various LivingSocial engineers.
        


slide: 34

	While I focused on code analysis to understand what a system
	is doing and finding unused code paths. Obviously there are a
	lot of other amazing production code analysis tools. Ruby
	historically hasn't been very good it has been improving.
	We have members of the community that are
	working on making better.

	So I wanted to point out some other gems and tools that can
	either help you understand what is going on with your system
	or with the performance of the code as it runs. Some of these
	tools can be used in production while others are a probably
	best in development only until the tooling gets better.
	
	Anything by by Aman Gupta is generally awesome. Not only has
      he released amazing gems and tools. He is now on the frontline
      improving the Ruby  
      back to clients.

	Sam Rawlins has been doing amazing work related to GC tools to
      help you understand what is going on on systems. I recommend his
      MtnWestRuby talk

	change.org has related a interesting MethodProfiler tool.

	Simeon Willbanks has a interesting tool that will collect
      method cache invalidations for Ruby 2.1

	A lot of great work is going on to help give us better
      insights into what is happening with our code on production.


slide: 35

	I wanted to say thanks to LivingSocial who lets me work some
      of these tools and sends me around to some conferences. Also, if
      you think any of this is interesting we are hiring.

	Thanks for listening, hope you found some of this interesting.
